# -*- coding: utf-8 -*-
"""ADS-GAN (Anonymization Through Data Synthesis Using Generative Adversarial Networks).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pMdH5XZE54_YZc7UHyp8TjXkjmGLyWL4

# Sintesis Data dengan Library synthcity
Lakukan sintesis data dengan library synthcity dengan plugin Bayesian Network, sintesis berjumlah 500 sampel

## Data loading

### Subtask:
Load the dataset "data_terbaru.csv" into a pandas DataFrame.

**Reasoning**:
Load the dataset "data_terbaru.csv" into a pandas DataFrame and display its first few rows and shape.
"""

import pandas as pd

try:
    df = pd.read_csv('data_terbaru.csv')
    display(df.head())
    print(df.shape)
except FileNotFoundError:
    print("Error: 'data_terbaru.csv' not found.")
    df = None
except pd.errors.ParserError:
    print("Error: Could not parse 'data_terbaru.csv'. Check file format.")
    df = None
except Exception as e:
    print(f"An unexpected error occurred: {e}")
    df = None



"""## Data preparation

### Subtask:
Prepare the loaded data for synthetic data generation using the synthcity library.

**Reasoning**:
Handle missing values, encode categorical features, validate data types, and create a copy of the modified DataFrame.
"""

# Check for missing values
print(df.isnull().sum())

# No missing values found in the provided head, so no imputation or removal is needed.

# Identify categorical features and apply one-hot encoding if necessary.
# Based on the provided head, 'GRUP' might be categorical.  Check unique values.
print(df['GRUP'].unique())

# If 'GRUP' has a limited number of unique values, it's categorical.  Let's assume it is.
# We'll use one-hot encoding.  If 'GRUP' contains more unique values, revise accordingly.

# One-hot encode 'GRUP'
df = pd.get_dummies(df, columns=['GRUP'], prefix=['GRUP'])

# Data Type Validation (ensure numerical columns are numeric)
for col in ['BPMJ', 'BPMP', 'SPOJ', 'SPOP', 'SUHUJ', 'SUHUP']:
    if not pd.api.types.is_numeric_dtype(df[col]):
        try:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            print(f"Column '{col}' converted to numeric.")
        except Exception as e:
            print(f"Error converting '{col}' to numeric: {e}")


# Create a copy of the modified DataFrame
df_prepared = df.copy()

display(df_prepared.head())

"""## Model training

### Subtask:
Train a Bayesian Network model using the synthcity library on the prepared data.
"""

import pandas as pd
real_data = pd.read_csv("/content/data_terbaru.csv")

from synthcity.plugins import Plugins
Plugins(categories=["generic", "privacy"]).list()

syn_model = Plugins().get("adsgan")
syn_model.fit(real_data)

synthetic_adsgan = syn_model.generate(count=1000)
#print(synthetic_adsgan)

"""## Model  Evaluation

### KS Test
"""

# Periksa statistik deskriptif dari data asli
print("Statistik Data Asli:")
print(real_data.describe())

# Periksa statistik deskriptif dari data sintetis
print("\nStatistik Data Sintetis:")
synthetic_adsgan = synthetic_adsgan.dataframe()
print(synthetic_adsgan.describe())

import pandas as pd
from scipy.stats import ks_2samp

# Membuat DataFrame
data_asli = pd.DataFrame(real_data)
data_sintesis = pd.DataFrame(synthetic_adsgan)

# Melakukan uji Kolmogorov-Smirnov untuk setiap kolom
ks_results_ads = {col: ks_2samp(data_asli[col], data_sintesis[col]) for col in real_data.keys()}

ks_results_ads

from synthcity.utils.serialization import load, load_from_file, save, save_to_file
buff = save(syn_model)
type(buff)

reloaded = load(buff)
reloaded.name()

synthetic_adsgan.to_csv('sampel000_adsgan.csv', index=True)

from synthcity.plugins.core.dataloader import DataLoader

from synthcity.plugins.core.models.tabular_gan import TabularGAN

from synthcity.plugins.core.dataloader import GenericDataLoader

generic_loader = GenericDataLoader(real_data)

from synthcity.plugins.core.dataloader import GenericDataLoader
from synthcity.benchmark import Benchmarks
import pprint

# Bungkus data asli dan sintetis
real_loaderr = GenericDataLoader(data_asli, target_column=None)
synthetic_loaderr = GenericDataLoader(synthetic_adsgan, target_column=None)

# Tes dan metrik
tests = [("custom_generator", "synthetic", synthetic_loaderr)]  # custom_generator = nama plugin bebas
metrics = {
    "statistical": {},
    "privacy": {}
}

from synthcity.benchmark import Benchmarks

results_ads = Benchmarks.evaluate(
    tests=[("marginal_distributions", "marginal_distributions", {})],
    X=real_loaderr,  # ini data asli
    synthetic=synthetic_loaderr,
    synthetic_size=1000,
    repeats=1
)


# Tampilkan hasil
pprint.pprint(results_ads)

"""### Corelattion Matrix

Mengukur hubungan linier antar variabel numerik. Kita bandingkan korelasi antar kolom di data asli vs sintetis. Jika beda jauh ‚Üí struktur hubungan rusak.

* Di dalam data sintetis itu sendiri (apakah masuk akal dan konsisten), dan

* Antara data sintetis dan data asli (apakah pola-pola hubungan antarkolom tetap terjaga).
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load data
df_real = pd.read_csv("data_terbaru.csv")
df_synth = pd.read_csv("/content/sampel000_adsgan.csv")

# Hitung korelasi
corr_real = df_real.corr(numeric_only=True)
corr_synth = df_synth.corr(numeric_only=True)

df_synth.shape

# Plot perbandingan korelasi
fig, axs = plt.subplots(1, 2, figsize=(12, 5))
sns.heatmap(corr_real, ax=axs[0], annot=True, cmap="Blues", cbar=False)
axs[0].set_title("Korelasi Data Asli")

sns.heatmap(corr_synth, ax=axs[1], annot=True, cmap="Greens", cbar=False)
axs[1].set_title("Korelasi Data Sintetis (ads gan)")

plt.tight_layout()
plt.show()

"""### PCA (Principal Component Analysis)

Mengurangi dimensi & memvisualisasikan data. Jika pola distribusi komponen utama berbeda antara asli dan sintetis ‚Üí struktur data berbeda.
"""

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Reload data
df_real = pd.read_csv("data_terbaru.csv")
df_synth = pd.read_csv("/content/sampel000_adsgan.csv")

# Ambil hanya kolom numerik dan drop NaN jika ada
# Select only the common numeric columns for scaling
df_real_num = df_real.select_dtypes(include=['number']).dropna()
df_synth_num = df_synth.select_dtypes(include=['number']).dropna()
# Standarisasi data sebelum PCA
scaler = StandardScaler()
real_scaled = scaler.fit_transform(df_real_num)
synth_scaled = scaler.transform(df_synth_num)

# PCA - Ambil 2 komponen utama
pca = PCA(n_components=2)
real_pca = pca.fit_transform(real_scaled)
synth_pca = pca.transform(synth_scaled)

# Plotting hasil PCA
plt.figure(figsize=(10, 6))
plt.scatter(real_pca[:, 0], real_pca[:, 1], alpha=0.6, label='Data Asli', color='blue')
plt.scatter(synth_pca[:, 0], synth_pca[:, 1], alpha=0.6, label='Data Sintetis (ads gan)', color='green')
plt.xlabel('Komponen Utama 1')
plt.ylabel('Komponen Utama 2')
plt.title('Visualisasi PCA (2D) Data Asli vs Sintetis')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""### TSTR (Train on Synthetic, Test on Real)

Hasil data augmentasi dijadikan data training sedangkan data asli jadi data testing.

üß† Tujuan Uji Ini: Kita ingin tahu apakah data sintetik (hasil augmentasi) cukup berkualitas untuk melatih model yang tetap akurat saat diuji di data asli.

Dengan begitu, kamu bisa percaya bahwa data hasil augmentasi ini benar-benar punya "nilai fungsional".

#### RF
"""

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report

df_real = pd.read_csv("/content/data_terbaru.csv")
df_adsgan = pd.read_csv("/content/sampel000_adsgan.csv")

def get_X_y(df):
    X = df.drop(columns=["GRUP"])
    y = df["GRUP"]
    return X, y

X_real, y_real = get_X_y(df_real)
X_df_adsgan, y_df_adsgan = get_X_y(df_adsgan)

# Get the common columns between the two DataFrames
common_cols = X_real.columns.intersection(X_df_adsgan.columns)

# Select only these common columns for scaling
X_df_adsgan_scaled = scaler.fit_transform(X_df_adsgan[common_cols])
X_real_scaled = scaler.transform(X_real[common_cols])

# ü§ñ Model: Train di Bayesian, Test di Data Asli
# ======================
model_adsgan = RandomForestClassifier(random_state=42)
model_adsgan.fit(X_df_adsgan_scaled, y_df_adsgan) # Changed y_bn to y_df_bn

# Drop 'Unnamed: 0' before fitting
#X_bn = X_bn.drop(columns=['Unnamed: 0'], errors='ignore')
# errors='ignore' prevents error if the column doesn't exist

# üß™ Test di data asli
y_pred_adsgan = model_adsgan.predict(X_real_scaled)

# üìä Evaluasi performa
print("üìä Performance (Train on adsgan ‚Üí Test on REAL):")
print(classification_report(y_real, y_pred_adsgan))

"""**HYPERPARAMETER TUNING**"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report

# Inisialisasi model dasar
model_rf = RandomForestClassifier(random_state=42)

# Ruang hyperparameter
grid_space = {
    'max_depth': [3, 5, 10, None],
    'n_estimators': [10, 100, 200],
    'max_features': [1, 3, 5, 7],
    'min_samples_leaf': [1, 2, 3],
    'min_samples_split': [2, 3]  # ‚Üê fix: tidak boleh 1
}

# Grid Search dengan cross-validation 3-fold
grid = GridSearchCV(
    model_rf,
    param_grid=grid_space,
    cv=3,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)
# Lakukan tuning: train di data sintetik BAYESIAN
grid.fit(X_df_adsgan_scaled, y_df_adsgan)

# Gunakan model terbaik untuk prediksi di data asli
best_model = grid.best_estimator_
y_pred = best_model.predict(X_real_scaled)

# Tampilkan hasil evaluasi
print("üìà Best Params:", grid.best_params_)
print("\nüìä Evaluation (After Tuning):")
print(classification_report(y_real, y_pred))

"""#### LR"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

df_real = pd.read_csv("/content/data_terbaru.csv")
df_adsgan = pd.read_csv("/content/sampel000_adsgan.csv")

# Fungsi bantu tetap sama
def get_X_y(df):
    X = df.drop(columns=["GRUP"])
    y = df["GRUP"]
    return X, y

# Ambil data training & testing
X_real, y_real = get_X_y(df_real)
X_adsgan, y_adsgan = get_X_y(df_adsgan)

# Bersihkan kolom jika ada 'Unnamed: 0'
X_adsgan = X_adsgan.drop(columns=['Unnamed: 0'], errors='ignore')
X_real = X_real.drop(columns=['Unnamed: 0'], errors='ignore')

# üîÑ Standardisasi fitur
scaler = StandardScaler()
X_adsgan_scaled = scaler.fit_transform(X_adsgan)
X_real_scaled = scaler.transform(X_real)

# üîß Inisialisasi model LogisticRegression
model_logreg = LogisticRegression(max_iter=1000, solver='liblinear')

# ü§ñ Train di data sintetik
model_logreg.fit(X_adsgan_scaled, y_adsgan)

# üß™ Uji di data asli
y_pred_logreg = model_logreg.predict(X_real_scaled)

# Tampilkan hasil evaluasi
print("üìä Performance (Train on adsgan ‚Üí Test on REAL) - LogisticRegression:")
print(classification_report(y_real, y_pred_logreg))

"""**HYPERPARAMETER TUNING**"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report

# Bersihkan jika ada kolom tambahan
X_adsgan = X_adsgan.drop(columns=['Unnamed: 0'], errors='ignore')
X_real = X_real.drop(columns=['Unnamed: 0'], errors='ignore')

# Definisikan model dasar
logreg = LogisticRegression()

# Parameter grid untuk tuning
param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear'],  # liblinear support l1 & l2
    'max_iter': [100, 300, 1000]
}

# Inisialisasi GridSearch
grid = GridSearchCV(
    estimator=logreg,
    param_grid=param_grid,
    scoring='accuracy',
    cv=3,
    verbose=1,
    n_jobs=-1
)
# üöÄ Tuning dengan data sintetik

grid.fit(X_df_adsgan_scaled, y_df_adsgan)

# Prediksi di data asli
best_logreg = grid.best_estimator_
y_pred_tuned = best_logreg.predict(X_real)

# Hasil akhir
print("üìå Best Params:", grid.best_params_)
print("\nüìä Performance (Logistic Regression TUNED ‚Äî Train on adsgan ‚Üí Test on REAL):")
print(classification_report(y_real, y_pred_tuned))

"""#### SVM"""

from sklearn.svm import SVC
from sklearn.metrics import classification_report

# Fungsi bantu
def get_X_y(df):
    X = df.drop(columns=["GRUP"])
    y = df["GRUP"]
    return X, y

# Ambil data training & testing
X_real, y_real = get_X_y(df_real)
X_adsgan, y_adsgan = get_X_y(df_adsgan)

# Bersihkan kolom 'Unnamed: 0' jika ada
X_adsgan = X_adsgan.drop(columns=['Unnamed: 0'], errors='ignore')
X_real = X_real.drop(columns=['Unnamed: 0'], errors='ignore')

# Inisialisasi model SVM
model_svm = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)

# üöÄ Train model di data sintetik (DP GAN)
model_svm.fit(X_adsgan, y_adsgan)

# üß™ Test model di data asli
y_pred_svm = model_svm.predict(X_real)

# üìä Tampilkan hasil evaluasi
print("üìä Performance (SVM ‚Äî Train on adsgan ‚Üí Test on REAL):")
print(classification_report(y_real, y_pred_svm))

"""**HYPERPARAMETER TUNING**"""

from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report

# Bersihkan kolom jika ada 'Unnamed: 0'
X_adsgan = X_adsgan.drop(columns=['Unnamed: 0'], errors='ignore')
X_real = X_real.drop(columns=['Unnamed: 0'], errors='ignore')

# Definisikan model dasar
svm = SVC()

# Parameter grid
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto', 0.01, 0.1, 1],
    'kernel': ['rbf', 'linear']
}

# Setup GridSearch
grid = GridSearchCV(
    estimator=svm,
    param_grid=param_grid,
    scoring='accuracy',
    cv=3,
    verbose=1,
    n_jobs=-1
)

# üöÄ Training model di data sintetik (Bayesian)
grid.fit(X_df_adsgan_scaled, y_df_adsgan)

# üß™ Uji di data asli
best_svm = grid.best_estimator_
y_pred_tuned_svm = best_svm.predict(X_real)

# üìù Hasil
print("üìå Best Hyperparameters (SVM):", grid.best_params_)
print("\nüìä Performance (TUNED SVM ‚Äî Train on adsgan ‚Üí Test on REAL):")
print(classification_report(y_real, y_pred_tuned_svm))