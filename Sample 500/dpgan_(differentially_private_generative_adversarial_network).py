# -*- coding: utf-8 -*-
"""DPGAN (Differentially Private Generative Adversarial Network).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oXjTAV9JDwdOIHdx6z0OiqdrzpyHVKej

# Sintesis Data dengan Library synthcity
Lakukan sintesis data dengan library synthcity dengan plugin Bayesian Network, sintesis berjumlah 500 sampel

## Data loading

### Subtask:
Load the dataset "data_terbaru.csv" into a pandas DataFrame.

**Reasoning**:
Load the dataset "data_terbaru.csv" into a pandas DataFrame and display its first few rows and shape.
"""

import pandas as pd

try:
    df = pd.read_csv('data_terbaru.csv')
    display(df.head())
    print(df.shape)
except FileNotFoundError:
    print("Error: 'data_terbaru.csv' not found.")
    df = None
except pd.errors.ParserError:
    print("Error: Could not parse 'data_terbaru.csv'. Check file format.")
    df = None
except Exception as e:
    print(f"An unexpected error occurred: {e}")
    df = None



"""## Data preparation

### Subtask:
Prepare the loaded data for synthetic data generation using the synthcity library.

**Reasoning**:
Handle missing values, encode categorical features, validate data types, and create a copy of the modified DataFrame.
"""

# Check for missing values
print(df.isnull().sum())

# No missing values found in the provided head, so no imputation or removal is needed.

# Identify categorical features and apply one-hot encoding if necessary.
# Based on the provided head, 'GRUP' might be categorical.  Check unique values.
print(df['GRUP'].unique())

# If 'GRUP' has a limited number of unique values, it's categorical.  Let's assume it is.
# We'll use one-hot encoding.  If 'GRUP' contains more unique values, revise accordingly.

# One-hot encode 'GRUP'
df = pd.get_dummies(df, columns=['GRUP'], prefix=['GRUP'])

# Data Type Validation (ensure numerical columns are numeric)
for col in ['BPMJ', 'BPMP', 'SPOJ', 'SPOP', 'SUHUJ', 'SUHUP']:
    if not pd.api.types.is_numeric_dtype(df[col]):
        try:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            print(f"Column '{col}' converted to numeric.")
        except Exception as e:
            print(f"Error converting '{col}' to numeric: {e}")


# Create a copy of the modified DataFrame
df_prepared = df.copy()

display(df_prepared.head())

"""## Model training

### Subtask:
Train a DP GAN model using the synthcity library on the prepared data.
"""

real = pd.read_csv("/content/data_terbaru.csv")

syn_model_dpgan = Plugins().get("dpgan")
syn_model_dpgan .fit(real)

synthetic_dpgan = syn_model_dpgan.generate(count=500)

"""## Model  Evaluation

### KS Test
"""

# Periksa statistik deskriptif dari data asli
print("Statistik Data Asli:")
print(real.describe())

# Periksa statistik deskriptif dari data sintetis
print("\nStatistik Data Sintetis:")
synthetic_dpgan = synthetic_dpgan.dataframe()
print(synthetic_dpgan.describe())

import pandas as pd
from scipy.stats import ks_2samp

# Membuat DataFrame
dt_real = pd.DataFrame(real)
dt_synthetic = pd.DataFrame(synthetic_dpgan)

# Melakukan uji Kolmogorov-Smirnov untuk setiap kolom
ks_results_dp = {col: ks_2samp(dt_real[col], dt_synthetic[col]) for col in real.keys()}

ks_results_dp

from synthcity.utils.serialization import load, load_from_file, save, save_to_file
buff = save(syn_model_dpgan)
type(buff)

reloaded = load(buff)
reloaded.name()

synthetic_dpgan.to_csv('sampel500_dpgan.csv', index=True)

from synthcity.plugins.core.dataloader import DataLoader

from synthcity.plugins.core.models.tabular_gan import TabularGAN

from synthcity.plugins.core.dataloader import GenericDataLoader

generic_loader = GenericDataLoader(real)

torch_dataloader = load(buff)

from synthcity.plugins.core.dataloader import GenericDataLoader
from synthcity.benchmark import Benchmarks
import pprint

# Bungkus data asli dan sintetis
real_loaderrrr = GenericDataLoader(dt_real, target_column=None)
synthetic_loaderrrr = GenericDataLoader(synthetic_dpgan, target_column=None)

# Tes dan metrik
tests = [("custom_generator", "synthetic", synthetic_loaderrrr)]  # custom_generator = nama plugin bebas
metrics = {
    "statistical": {},
    "privacy": {}
}

from synthcity.benchmark import Benchmarks

results_dp = Benchmarks.evaluate(
    tests=[("marginal_distributions", "marginal_distributions", {})],
    X=real_loaderrrr,  # ini data asli
    synthetic=synthetic_loaderrrr,
    synthetic_size=500,
    repeats=1
)


# Tampilkan hasil
pprint.pprint(results_dp)

"""### Corelattion Matrix

Mengukur hubungan linier antar variabel numerik. Kita bandingkan korelasi antar kolom di data asli vs sintetis. Jika beda jauh ‚Üí struktur hubungan rusak.

* Di dalam data sintetis itu sendiri (apakah masuk akal dan konsisten), dan

* Antara data sintetis dan data asli (apakah pola-pola hubungan antarkolom tetap terjaga).
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load data
df_real = pd.read_csv("data_terbaru.csv")
df_synth = pd.read_csv("/content/sampel500_dpgan.csv")

# Hitung korelasi
corr_real = df_real.corr(numeric_only=True)
corr_synth = df_synth.corr(numeric_only=True)

# Plot perbandingan korelasi
fig, axs = plt.subplots(1, 2, figsize=(12, 5))
sns.heatmap(corr_real, ax=axs[0], annot=True, cmap="Blues", cbar=False)
axs[0].set_title("Korelasi Data Asli")

sns.heatmap(corr_synth, ax=axs[1], annot=True, cmap="Greens", cbar=False)
axs[1].set_title("Korelasi Data Sintetis (Bayesian)")

plt.tight_layout()
plt.show()

"""### PCA (Principal Component Analysis)

Mengurangi dimensi & memvisualisasikan data. Jika pola distribusi komponen utama berbeda antara asli dan sintetis ‚Üí struktur data berbeda.
"""

import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Reload data
df_real = pd.read_csv("data_terbaru.csv")
df_synth = pd.read_csv("/content/sampel500_dpgan.csv")

# Ambil hanya kolom numerik dan drop NaN jika ada
df_real_num = df_real.select_dtypes(include=['float64', 'int64']).dropna()
df_synth_num = df_synth.select_dtypes(include=['float64', 'int64']).dropna()

# Standarisasi data sebelum PCA
scaler = StandardScaler()
real_scaled = scaler.fit_transform(df_real_num)
synth_scaled = scaler.transform(df_synth_num)

# PCA - Ambil 2 komponen utama
pca = PCA(n_components=2)
real_pca = pca.fit_transform(real_scaled)
synth_pca = pca.transform(synth_scaled)

# Plotting hasil PCA
plt.figure(figsize=(10, 6))
plt.scatter(real_pca[:, 0], real_pca[:, 1], alpha=0.6, label='Data Asli', color='blue')
plt.scatter(synth_pca[:, 0], synth_pca[:, 1], alpha=0.6, label='Data Sintetis (DP GAN)', color='green')
plt.xlabel('Komponen Utama 1')
plt.ylabel('Komponen Utama 2')
plt.title('Visualisasi PCA (2D) Data Asli vs Sintetis')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Plotting hasil PCA
plt.figure(figsize=(10, 6))
plt.scatter(real_pca[:, 0], real_pca[:, 1], alpha=0.6, label='Data Asli', color='blue')
plt.scatter(synth_pca[:, 0], synth_pca[:, 1], alpha=0.6, label='Data Sintetis (Bayesian)', color='green')
plt.xlabel('Komponen Utama 1')
plt.ylabel('Komponen Utama 2')
plt.title('Visualisasi PCA (2D) Data Asli vs Sintetis')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""### TSTR (Train on Synthetic, Test on Real)

Hasil data augmentasi dijadikan data training sedangkan data asli jadi data testing.

üß† Tujuan Uji Ini: Kita ingin tahu apakah data sintetik (hasil augmentasi) cukup berkualitas untuk melatih model yang tetap akurat saat diuji di data asli.

Dengan begitu, kamu bisa percaya bahwa data hasil augmentasi ini benar-benar punya "nilai fungsional".

#### RF
"""

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report

df_real = pd.read_csv("/content/data_terbaru.csv")
df_dpgan = pd.read_csv("/content/sampel500_dpgan.csv")

df_real.shape[0]  # Menampilkan jumlah baris

df_dpgan.shape[0]

df_dpgan.head()

def get_X_y(df):
    X = df.drop(columns=["GRUP"])
    y = df["GRUP"]
    return X, y

X_real, y_real = get_X_y(df_real)
X_dpgan, y_dpgan = get_X_y(df_dpgan)

scaler = StandardScaler()
X_dpgan_scaled = scaler.fit_transform(X_dpgan)
X_real_scaled = scaler.transform(X_real)

# ü§ñ Model: Train di Bayesian, Test di Data Asli
# ======================
model_dpgan = RandomForestClassifier(random_state=42)
model_dpgan.fit(X_dpgan_scaled, y_dpgan)

# Drop 'Unnamed: 0' before fitting
X_dpgan = X_dpgan.drop(columns=['Unnamed: 0'], errors='ignore')
# errors='ignore' prevents error if the column doesn't exist

# üß™ Test di data asli
y_pred_dpgan = model_dpgan.predict(X_real_scaled)

# üìä Evaluasi performa
print("üìä Performance (Train on DP GAN ‚Üí Test on REAL):")
print(classification_report(y_real, y_pred_dpgan))

"""**HYPERPARAMETER TUNING**"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report

# Inisialisasi model dasar
model_rf = RandomForestClassifier(random_state=42)

# Ruang hyperparameter
grid_space = {
    'max_depth': [3, 5, 10, None],
    'n_estimators': [10, 100, 200],
    'max_features': [1, 3, 5, 7],
    'min_samples_leaf': [1, 2, 3],
    'min_samples_split': [2, 3]  # ‚Üê fix: tidak boleh 1
}

# Grid Search dengan cross-validation 3-fold
grid = GridSearchCV(
    model_rf,
    param_grid=grid_space,
    cv=3,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)
# Lakukan tuning: train di data sintetik BAYESIAN
grid.fit(X_dpgan, y_dpgan)

# Gunakan model terbaik untuk prediksi di data asli
best_model = grid.best_estimator_
y_pred = best_model.predict(X_real)

# Tampilkan hasil evaluasi
print("üìà Best Params:", grid.best_params_)
print("\nüìä Evaluation (After Tuning):")
print(classification_report(y_real, y_pred))

"""#### LR"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# Fungsi bantu tetap sama
def get_X_y(df):
    X = df.drop(columns=["GRUP"])
    y = df["GRUP"]
    return X, y

# Ambil data training & testing
X_real, y_real = get_X_y(df_real)
X_dpgan, y_dpgan = get_X_y(df_dpgan)

# Bersihkan kolom jika ada 'Unnamed: 0'
X_dpgan = X_dpgan.drop(columns=['Unnamed: 0'], errors='ignore')
X_real = X_real.drop(columns=['Unnamed: 0'], errors='ignore')

# üîÑ Standardisasi fitur
scaler = StandardScaler()
X_dpgan_scaled = scaler.fit_transform(X_dpgan)
X_real_scaled = scaler.transform(X_real)

# üîß Inisialisasi model LogisticRegression
model_logreg = LogisticRegression(max_iter=1000, solver='liblinear')

# ü§ñ Train di data sintetik
model_logreg.fit(X_dpgan_scaled, y_dpgan)

# üß™ Uji di data asli
y_pred_logreg = model_logreg.predict(X_real_scaled)

# Tampilkan hasil evaluasi
print("üìä Performance (Train on DP GAN ‚Üí Test on REAL) - LogisticRegression:")
print(classification_report(y_real, y_pred_logreg))

"""**HYPERPARAMETER TUNING**"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report

# Bersihkan jika ada kolom tambahan
X_dpgan = X_dpgan.drop(columns=['Unnamed: 0'], errors='ignore')
X_real = X_real.drop(columns=['Unnamed: 0'], errors='ignore')

# Definisikan model dasar
logreg = LogisticRegression()

# Parameter grid untuk tuning
param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear'],  # liblinear support l1 & l2
    'max_iter': [100, 300, 1000]
}

# Inisialisasi GridSearch
grid = GridSearchCV(
    estimator=logreg,
    param_grid=param_grid,
    scoring='accuracy',
    cv=3,
    verbose=1,
    n_jobs=-1
)
# üöÄ Tuning dengan data sintetik
grid.fit(X_dpgan, y_dpgan)

# Prediksi di data asli
best_logreg = grid.best_estimator_
y_pred_tuned = best_logreg.predict(X_real)

# Hasil akhir
print("üìå Best Params:", grid.best_params_)
print("\nüìä Performance (Logistic Regression TUNED ‚Äî Train on DP GAN ‚Üí Test on REAL):")
print(classification_report(y_real, y_pred_tuned))

"""#### SVM"""

from sklearn.svm import SVC
from sklearn.metrics import classification_report

# Fungsi bantu
def get_X_y(df):
    X = df.drop(columns=["GRUP"])
    y = df["GRUP"]
    return X, y

# Ambil data training & testing
X_real, y_real = get_X_y(df_real)
X_dpgan, y_dpgan = get_X_y(df_dpgan)

# Bersihkan kolom 'Unnamed: 0' jika ada
X_dpgan = X_dpgan.drop(columns=['Unnamed: 0'], errors='ignore')
X_real = X_real.drop(columns=['Unnamed: 0'], errors='ignore')

# Inisialisasi model SVM
model_svm = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)

# üöÄ Train model di data sintetik (DP GAN)
model_svm.fit(X_dpgan, y_dpgan)

# üß™ Test model di data asli
y_pred_svm = model_svm.predict(X_real)

# üìä Tampilkan hasil evaluasi
print("üìä Performance (SVM ‚Äî Train on DP GAN ‚Üí Test on REAL):")
print(classification_report(y_real, y_pred_svm))

"""**HYPERPARAMETER TUNING**"""

from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report

# Bersihkan kolom jika ada 'Unnamed: 0'
X_dpgan = X_dpgan.drop(columns=['Unnamed: 0'], errors='ignore')
X_real = X_real.drop(columns=['Unnamed: 0'], errors='ignore')

# Definisikan model dasar
svm = SVC()

# Parameter grid
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto', 0.01, 0.1, 1],
    'kernel': ['rbf', 'linear']
}

# Setup GridSearch
grid = GridSearchCV(
    estimator=svm,
    param_grid=param_grid,
    scoring='accuracy',
    cv=3,
    verbose=1,
    n_jobs=-1
)

# üöÄ Training model di data sintetik (Bayesian)
grid.fit(X_dpgan, y_dpgan)

# üß™ Uji di data asli
best_svm = grid.best_estimator_
y_pred_tuned_svm = best_svm.predict(X_real)

# üìù Hasil
print("üìå Best Hyperparameters (SVM):", grid.best_params_)
print("\nüìä Performance (TUNED SVM ‚Äî Train on DP GAN ‚Üí Test on REAL):")
print(classification_report(y_real, y_pred_tuned_svm))